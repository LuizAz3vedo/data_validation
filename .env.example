# ============================================
# LLM PROVIDER - Escolha: ollama, openai, anthropic
# ============================================
LLM_PROVIDER=ollama

# ============================================
# OLLAMA (Local - Recomendado)
# ============================================
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:14b

# Timeout maior para modelos locais (em segundos)
OLLAMA_TIMEOUT=120

# ============================================
# OPENAI (Cloud - Opcional)
# ============================================
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini

# ============================================
# ANTHROPIC (Cloud - Opcional)
# ============================================
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-haiku-20240307

# ============================================
# MODEL GERAL (usado pelo Instructor)
# ============================================
LLM_MODEL=qwen2.5:14b

# ============================================
# REDIS
# ============================================
REDIS_URL=redis://localhost:6379/0
CACHE_TTL_SECONDS=3600
CACHE_ENABLED=true

# ============================================
# API
# ============================================
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true

# ============================================
# RATE LIMITING
# ============================================
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW_SECONDS=60

# ============================================
# RETRY (aumentar para modelos locais)
# ============================================
MAX_RETRIES=3
RETRY_DELAY_SECONDS=2
